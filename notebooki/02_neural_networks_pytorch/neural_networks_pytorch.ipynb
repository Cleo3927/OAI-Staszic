{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Wprowadzenie do sieci neuronowych i biblioteki PyTorch\n",
    "\n",
    "Ten notatnik wprowadza krok po kroku:\n",
    "- czym są **tensory** w PyTorch i jak przypominają tablice NumPy,\n",
    "- podstawowe atrybuty tensora (`size`, `dtype`, `device`, `requires_grad`),\n",
    "- mechanizm **autograd** i funkcję `backward()`,\n",
    "- tworzenie własnych modeli dziedziczących po `torch.nn.Module`,\n",
    "- składanie modułów w większe sieci,\n",
    "- przykład trenowania prostej sieci neuronowej na zbiorze **MNIST** (rozpoznawanie odręcznych cyfr) wraz z wizualizacjami."
   ],
   "id": "c3da85fca2d0928c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Ustawienie losowości (dla powtarzalności eksperymentów)\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Wybór urządzenia: GPU (cuda), jeśli dostępne, w przeciwnym razie CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"Using device:\", device)"
   ],
   "id": "caaa75b510b1dd9d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Tensory w PyTorch i ich związek z NumPy\n",
    "\n",
    "Tensory w PyTorch są bardzo podobne do tablic (`ndarray`) w NumPy:\n",
    "\n",
    "- przechowują dane numeryczne w wielu wymiarach,\n",
    "- wspierają operacje wektorowe i macierzowe,\n",
    "- mogą być przenoszone na GPU (`device='cuda'`) - karty graficzne przyspieszające obliczenia,\n",
    "- mogą śledzić operacje potrzebne do automatycznego liczenia gradientów.\n",
    "\n",
    "Poniżej kilka prostych przykładów tworzenia tensorów i tablic NumPy.\n"
   ],
   "id": "e4d5c4fdb8888438"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Przykład: konwersja tablicy NumPy na tensor PyTorch\n",
    "x_np = np.array([[1, 2, 3], [4, 5, 6]])  # tablica NumPy\n",
    "x_torch = torch.tensor([[1, 2, 3], [4, 5, 6]])  # tensor PyTorch\n",
    "\n",
    "print(\"NumPy array:\")\n",
    "print(x_np)\n",
    "print(\"\\nTorch tensor:\")\n",
    "print(x_torch)"
   ],
   "id": "d1107ad43d2b4a70"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tworzenie tablic / tensorów wypełnionych zerami, jedynkami itd.\n",
    "# Bardzo podobne API w NumPy i PyTorch\n",
    "\n",
    "# NumPy\n",
    "zeros_np = np.zeros((2, 3))\n",
    "ones_np = np.ones((2, 3))\n",
    "full_np = np.full((2, 3), fill_value=7)\n",
    "\n",
    "# PyTorch\n",
    "zeros_torch = torch.zeros((2, 3))\n",
    "ones_torch = torch.ones((2, 3))\n",
    "full_torch = torch.full((2, 3), fill_value=7)\n",
    "\n",
    "print(\"NumPy zeros:\\n\", zeros_np)\n",
    "print(\"NumPy ones:\\n\", ones_np)\n",
    "print(\"NumPy full:\\n\", full_np)\n",
    "print(\"\\nTorch zeros:\\n\", zeros_torch)\n",
    "print(\"\\nTorch ones:\\n\", ones_torch)\n",
    "print(\"\\nTorch full(7):\\n\", full_torch)"
   ],
   "id": "c703268beaa8535c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Funkcje *_like: tworzenie tensora o takim samym kształcie jak inny tensor\n",
    "x = torch.arange(6).reshape(2, 3)\n",
    "print(\"x =\")\n",
    "print(x)\n",
    "\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "ones_like_x = torch.ones_like(x)\n",
    "\n",
    "print(\"\\nzeros_like(x):\")\n",
    "print(zeros_like_x)\n",
    "print(\"\\nones_like(x):\")\n",
    "print(ones_like_x)"
   ],
   "id": "3db02ad9c5f47718"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Atrybuty tensora: `size`, `dtype`, `device`, `requires_grad`\n",
    "\n",
    "Każdy tensor ma kilka kluczowych atrybutów:\n",
    "\n",
    "- `size()` / `shape` – rozmiar (liczba wymiarów i ich długości),\n",
    "- `dtype` – typ przechowywanych danych (np. `torch.float32`, `torch.int64`),\n",
    "- `device` – gdzie przechowywany jest tensor (CPU / GPU),\n",
    "- `requires_grad` – czy tensor ma śledzić operacje w celu liczenia gradientu.\n",
    "\n",
    "Zobaczmy to na przykładzie."
   ],
   "id": "736658967435379b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(x_np.shape, x_np.dtype)\n",
    "print(x.shape, x.dtype, x.device, x.requires_grad)"
   ],
   "id": "4df5c1e340249fb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tensor z konkretnym typem i włączonym liczeniem gradientów\n",
    "t = torch.tensor(\n",
    "    [[1.0, 2.0], [3.0, 4.0]],\n",
    "    dtype=torch.float32,\n",
    "    device=device,  # domyślnie 'cpu'\n",
    "    requires_grad=True,\n",
    ")\n",
    "\n",
    "print(\"Tensor t:\")\n",
    "print(t)\n",
    "print(\"\\nshape:\", t.shape)      # albo t.size()\n",
    "print(\"dtype:\", t.dtype)\n",
    "print(\"device:\", t.device)\n",
    "print(\"requires_grad:\", t.requires_grad)"
   ],
   "id": "9daba2d1b8fd4cd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Przenoszenie tensora między urządzeniami\n",
    "# (zadziała tylko, jeśli masz GPU; w przeciwnym razie pozostanie na CPU)\n",
    "cpu_tensor = torch.ones((2, 2))\n",
    "print(\"Domyślny device:\", cpu_tensor.device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor = cpu_tensor.to(\"cuda\")\n",
    "    print(\"Po przeniesieniu na GPU:\", gpu_tensor.device)\n",
    "else:\n",
    "    print(\"GPU niedostępne w tym środowisku.\")"
   ],
   "id": "137e2ec72d8c0a70"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Podstawowe operacje na tensorach\n",
    "\n",
    "PyTorch wspiera typowe operacje numeryczne:\n",
    "\n",
    "- dodawanie, odejmowanie, mnożenie element-po-elemencie,\n",
    "- iloczyn macierzowy (`matmul` lub operator `@`),\n",
    "- funkcje nieliniowe (np. `relu`, `sigmoid`)."
   ],
   "id": "923fcdd1fcfb5fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "a = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = torch.tensor([[10.0, 20.0], [30.0, 40.0]])\n",
    "\n",
    "print(\"a + b =\")\n",
    "print(a + b)\n",
    "\n",
    "print(\"\\na * b (element-wise) =\")\n",
    "print(a * b)\n",
    "\n",
    "# Iloczyn macierzowy\n",
    "print(\"\\na @ b^T =\")\n",
    "print(a @ b.T)"
   ],
   "id": "3809414de1814ed2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Automatyczne różniczkowanie (pochodna) – `autograd` i metoda `backward()`\n",
    "\n",
    "Jedną z najważniejszych cech PyTorch jest **automatyczne liczenie pochodnych**.\n",
    "Jeśli tensor ma `requires_grad=True`, PyTorch śledzi operacje wykonywane na tym tensorze\n",
    "i potrafi policzyć gradient wyjścia względem tego tensora.\n",
    "\n",
    "Zobaczmy prosty przykład z funkcją jednowymiarową.\n"
   ],
   "id": "ba2446e9a7d47084"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Przykład z wektorem: y = średnia(x^2), x – wektor wartości\n",
    "x = torch.tensor([-2, -1, 0, 1, 2], dtype=torch.float32, requires_grad=True)\n",
    "y = (x ** 2).mean()\n",
    "print(\"x =\", x)\n",
    "print(\"y = mean(x^2) =\", y.item())\n",
    "\n",
    "y.backward()  # dy/dx liczone automatycznie\n",
    "print(\"Gradient dy/dx =\", x.grad)\n",
    "\n",
    "# Uwaga: jeśli kilka razy wywołujemy backward na tym samym tensorze to nasze gradienty się sumują,\n",
    "# często trzeba wcześniej wyzerować gradient: x.grad.zero_(), jeśli chcemy uniknąć kumulacji."
   ],
   "id": "8192e8c1679fb98b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Klasa `torch.nn.Module` i warstwa liniowa `Linear`\n",
    "\n",
    "Aby tworzyć własne sieci neuronowe, dziedziczymy po klasie `nn.Module`.\n",
    "W `__init__` definiujemy warstwy (np. `nn.Linear`, `nn.Parameter`), a w metodzie `forward`\n",
    "opisujemy przepływ danych przez te warstwy."
   ],
   "id": "cdba24a052d93eeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Prosty przykład: model z jedną warstwą liniową\n",
    "class SimpleLinearNet(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        # Warstwa liniowa: y = xW + b\n",
    "        # musimy pisać self żeby parametry były rejestrowane jako część modelu\n",
    "        self.W = torch.nn.Parameter(torch.randn(in_features, out_features))  # tworzymy wagę W jako macierz losową o wymiarach (in_features, out_features)\n",
    "        self.b = torch.nn.Parameter(torch.randn(out_features))  # tworzymy bias b jako wektor losowy o wymiarze (out_features)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # chcemy policzyc y = xW + b\n",
    "        return self.b + x @ self.W\n",
    "\n",
    "# Przykład użycia\n",
    "net = SimpleLinearNet(in_features=3, out_features=1)\n",
    "print(net)\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0]])  # pojedynczy przykład\n",
    "y = net(x)\n",
    "print(\"Wejście:\", x)\n",
    "print(\"Wyjście modelu:\", y)"
   ],
   "id": "1ce2b07528516802"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Składanie wielu warstw – większy model\n",
    "\n",
    "Sieci neuronowe składają się zwykle z wielu warstw i komponentów. Możemy je ze sobą łączyć i składać\n",
    "\n",
    "Poniżej prosty przykład małej sieci neuronowej z trzema warstwami ukrytymi i funkcjami aktywacji ReLU."
   ],
   "id": "ebd7c9f4cb8548d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SmallNet(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = SimpleLinearNet(input_dim, hidden_dim)\n",
    "        self.fc2 = SimpleLinearNet(hidden_dim, hidden_dim)\n",
    "        self.fc3 = torch.nn.Linear(hidden_dim, output_dim)  # możemy też użyć gotowej warstwy z nn.Linear która działa podobnie jak nasza SimpleLinearNet\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "mlp = SmallNet(input_dim=4, hidden_dim=8, output_dim=3)\n",
    "print(mlp)\n",
    "\n",
    "dummy_input = torch.randn(2, 4)  # batch_size=2\n",
    "dummy_output = mlp(dummy_input)\n",
    "print(\"Wyjście MLP dla przykładowych danych:\")\n",
    "print(dummy_output)"
   ],
   "id": "40106cec961c0ba1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BiggerNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BiggerNet, self).__init__()\n",
    "        self.net1 = SmallNet(4, 5, 5)\n",
    "        self.net2 = SmallNet(5, 3, 2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.net1(x)\n",
    "        x = self.net2(x)\n",
    "        return x\n",
    "\n",
    "bigger_mlp = BiggerNet()\n",
    "print(bigger_mlp)\n",
    "dummy_output_bigger = bigger_mlp(dummy_input)\n",
    "print(\"Wyjście BiggerNet dla przykładowych danych:\")\n",
    "print(dummy_output_bigger)"
   ],
   "id": "99740b17763bd627"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. Zbiór danych MNIST – odręczne cyfry\n",
    "\n",
    "MNIST to klasyczny zbiór danych zawierający obrazy cyfr 0–9 zapisywanych odręcznie.\n",
    "Każdy obraz ma rozmiar **28×28 pikseli** (odcienie szarości).\n",
    "\n",
    "PyTorch (a dokładniej `torchvision`) udostępnia gotowy dataset `datasets.MNIST` podzielony na zbiór treningowy i testowy."
   ],
   "id": "85d3be09feb77ba7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Transformacje danych: zamiana na tensor i normalizacja\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # konwersja z PIL / numpy do tensora (C x H x W) wersji obrazkowej w tensora (1 x 28 x 28) z wartościami w [0, 1]\n",
    "])\n",
    "\n",
    "data_dir = \"data\"  # katalog, w którym zostanie zapisany MNIST\n",
    "\n",
    "# Uwaga: jeśli nie masz internetu, pobieranie może się nie powieść.\n",
    "train_dataset = datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "print(\"Liczba przykładów treningowych:\", len(train_dataset))\n",
    "print(\"Liczba przykładów testowych:\", len(test_dataset))"
   ],
   "id": "312d1dc6abda7b64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size = 64\n",
    "\n",
    "# To jest wygodny standard na podawanie danych do sieci\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  # tasujemy dane treningowe, żeby trening był bardziej losowy\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(\"Liczba batchy w train_loader:\", len(train_loader))\n",
    "print(\"Liczba batchy w test_loader:\", len(test_loader))"
   ],
   "id": "11dfc2a790a1d706"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Podgląd kilku obrazków z etykietami\n",
    "images, labels = next(iter(train_loader))\n",
    "print(\"Kształt batcha obrazów:\", images.shape)  # (batch_size, 1, 28, 28)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(2, 4, i + 1)\n",
    "    ax.imshow(images[i].squeeze(0), cmap=\"gray\")\n",
    "    ax.set_title(f\"label: {labels[i].item()}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "7a2b074539e34ab1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. Prosta sieć neuronowa dla MNIST\n",
    "\n",
    "Zbudujemy prostą sieć neuronową, która dostaje na wejściu spłaszczony obraz 28×28 (czyli 784 piksele),\n",
    "kilka warstw ukrytych oraz wyjście o rozmiarze 10 (klasy cyfr 0–9)."
   ],
   "id": "d84ef11188b50040"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MNISTNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 64)\n",
    "        self.fc3 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.flatten(x, start_dim=1)  # spłaszczamy obraz (batch_size, 1, 28, 28) -> (batch_size, 784)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)  # bez softmax – użyjemy CrossEntropyLoss\n",
    "\n",
    "        return x\n",
    "\n",
    "model = MNISTNet().to(device)\n",
    "print(model)"
   ],
   "id": "ad62ca890a1e2d28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Pętla treningowa\n",
    "\n",
    "Schemat uczenia jest typowy:\n",
    "\n",
    "1. Pobieramy batch danych `(images, labels)`,\n",
    "2. Liczymy predykcję modelu,\n",
    "3. Obliczamy stratę (`loss`),\n",
    "4. Wywołujemy `loss.backward()` aby policzyć gradienty,\n",
    "5. Wywołujemy `optimizer.step()` aby zaktualizować wagi,\n",
    "6. (Opcjonalnie) liczymy dokładność na zbiorze treningowym i testowym,\n",
    "7. Zapisujemy wyniki, aby później je **zwizualizować**."
   ],
   "id": "19a50c15c583e57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # funkcja straty dla klasyfikacji wieloklasowej\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # optymalizator Adam, która aktualizuje wagi modelu\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):  # iterowanie się po epokach\n",
    "    model.train()  # ustawienie modelu w tryb treningowy\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:  # iterowanie się po batchach w zbiorze treningowym\n",
    "        images, labels = images.to(device), labels.to(device)  # przeniesienie danych na odpowiednie urządzenie i podział ich na obrazy i etykiety\n",
    "\n",
    "        optimizer.zero_grad()               # wyzerowanie gradientów z poprzedniego kroku inaczej będą się sumować\n",
    "        outputs = model(images)             # policzenie predykcji modelu dla danych\n",
    "        loss = criterion(outputs, labels)   # liczenie lossu\n",
    "        loss.backward()                     # liczenie gradientów\n",
    "        optimizer.step()                    # aktualizacja wag w modelu na podstawe gradientów\n",
    "\n",
    "        running_loss += loss.item() * labels.size(0)  # śledzenie łącznego lossu\n",
    "        _, predicted = outputs.max(1)  # przekształcenie wyników modelu na przewidywane klasy\n",
    "        total += labels.size(0)  # całkowita liczba przykładów\n",
    "        correct += (predicted == labels).sum().item()  # liczba poprawnych predykcji modelu - w ilu miejscach przewidział dobrze\n",
    "\n",
    "    epoch_loss = running_loss / total  # średni loss w tej epoce\n",
    "    epoch_acc = correct / total  # dokładność w tej epoce\n",
    "    train_losses.append(epoch_loss)  # zapisanie średniego lossu\n",
    "    train_accuracies.append(epoch_acc)  # zapisanie dokładności\n",
    "\n",
    "    # --- ewaluacja na zbiorze testowym ---\n",
    "    model.eval()  # ustawienie modelu w tryb ewaluacyjny - czasami wyniki na niektórych warstwach różnią się w trybie treningowym i ewaluacyjnym\n",
    "    test_running_loss = 0.0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():  # wyłączenie liczenia gradientów podczas ewaluacji - oszczędza pamięć i przyspiesza obliczenia\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_running_loss += loss.item() * labels.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_loss = test_running_loss / test_total\n",
    "    test_acc = test_correct / test_total\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch + 1}/{epochs}] \"\n",
    "        f\"train_loss={epoch_loss:.4f}, train_acc={epoch_acc:.4f}, \"\n",
    "        f\"test_loss={test_loss:.4f}, test_acc={test_acc:.4f}\"\n",
    "    )\n"
   ],
   "id": "6366d7c691d80d23"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. Wizualizacja procesu uczenia\n",
    "\n",
    "Mając zapisane wartości straty i dokładności w każdej epoce, możemy narysować wykresy,\n",
    "które ułatwią zrozumienie, czy model faktycznie się uczy."
   ],
   "id": "260956a4b6d4a3e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Wykres strat treningowych i testowych\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_losses, label=\"train loss\")\n",
    "plt.plot(test_losses, label=\"test loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss w trakcie uczenia\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Wykres dokładności\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(train_accuracies, label=\"train accuracy\")\n",
    "plt.plot(test_accuracies, label=\"test accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Dokładność w trakcie uczenia\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "9edccc80496c876d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Podgląd predykcji i błędnych klasyfikacji\n",
    "\n",
    "Na koniec obejrzymy kilka przykładów z zestawu testowego: co było etykietą prawdziwą,\n",
    "a co przewidział model."
   ],
   "id": "66bc6afe7cc66e15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.eval()\n",
    "images, labels = next(iter(test_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, preds = outputs.max(1)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "for i in range(8):\n",
    "    ax = fig.add_subplot(2, 4, i + 1)\n",
    "    ax.imshow(images[i].cpu().squeeze(0), cmap=\"gray\")\n",
    "    ax.set_title(f\"true: {labels[i].item()}\\npred: {preds[i].item()}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "3b77984b5fbe0521"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "621d382e3f20e8da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "464615cec8c8ee8b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
