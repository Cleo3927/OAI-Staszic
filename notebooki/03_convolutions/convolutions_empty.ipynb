{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## How to train your own model",
   "id": "12b793e1e258c3df"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Zacznijmyd od podstawowych importów i sprawdzenia jakie mamy możliwe środki do trenowania",
   "id": "4bf6b248ad460867"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "Dzisiaj będziemy pracować z bardziej skomplikowanym przykładem jakim jest [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html). Jest to zbiór obrazów o rozmiarze 32x32 pikseli, zawierający 10 klas obiektów. Możemy go pobrać z biblioteki torchvision."
   ],
   "id": "27a26317071bd11c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")"
   ],
   "id": "987f9f864e684de0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# teraz chcemy ustawić wielkość batcha i learning rate do trenowania\n",
    "\n",
    "# TODO: spróbuj pozmieniać wartości tych parametrów\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# i przygotować dataset do załadowania\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=1\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False, num_workers=1\n",
    ")"
   ],
   "id": "3e46d0a112a207eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Wizualizacja danych\n",
    "Zobaczmy jak wyglądają nasze dane. W tym celu użyjemy biblioteki matplotlib, aby wyświetlić kilka obrazów wraz z podpisami z naszego zbioru danych."
   ],
   "id": "be29383321fb33aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_images(images: torch.Tensor, labels: torch.Tensor, classes: list[str]) -> None:\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(1, len(images), i + 1)\n",
    "        plt.imshow(images[i].permute(1, 2, 0))  # permute to change from CxHxW to HxWxC\n",
    "        plt.title(classes[labels[i]])\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()"
   ],
   "id": "8647c983ce29e2ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# zobaczmy pierwsze 10 obrazków z naszego datasetu\n",
    "\n",
    "images, labels = next(iter(train_dataloader))\n",
    "show_images(images[:8], labels[:8], train_dataloader.dataset.classes)"
   ],
   "id": "fc04d679844aaef9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SimpleModel(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(SimpleModel, self).__init__()\n",
    "        ### TODO: zdefiniuj prostą sieć neuronową z 2 ukrytymi warstwami o rozmiarach 128 i 64\n",
    "        self.layer1 = torch.nn.Linear(32 * 32 * 3, 128)\n",
    "        self.layer2 = torch.nn.Linear(128, 64)\n",
    "        self.layer3 = torch.nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ### TODO: zaimplementuj funkcję forward z użyciem aktywacji ReLU pomiędzy warstwami, pamiętaj o spłaszczeniu wejścia"
   ],
   "id": "a6ba00fd0d85f24f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def validation_loop(\n",
    "    ### TODO: czego potrzebujemy do walidacji?\n",
    ") -> tuple[float, float]:\n",
    "    ### TODO: validacja modelu - zwróć średnią stratę i dokładność na zbiorze walidacyjnym\n",
    "\n",
    "def training_loop(\n",
    "    ### TODO: czego potrzebujemy do trenowania?\n",
    ") -> None:\n",
    "    ### TODO: implementacja pętli trenowania z użyciem tqdm do wizualizacji postępu"
   ],
   "id": "12b1c07dec613f9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "### TODO: trenowanie najmniejszego modelu\n",
   "id": "a1d9e8723d3a9626",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class SequentialModel(torch.nn.Module):\n",
    "    def __init__(self, layers: list[int]) -> None:\n",
    "        super(SequentialModel, self).__init__()\n",
    "\n",
    "        ### TODO: zdefiniuj model sekwencyjny na podstawie podanej listy rozmiarów warstw, użyj aktywacji ReLU pomiędzy warstwami,\n",
    "        ### hint: użyj torch.nn.Sequential oraz torch.nn.Linear\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ### TODO: zaimplementuj funkcję forward z użyciem spłaszczenia wejścia"
   ],
   "id": "dfe6adb4c0d53bd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_bigger = SequentialModel([256, 128, 128, 128, 64]).to(device)\n",
    "#### TODO: trenowanie większego modelu"
   ],
   "id": "6e6d3656bf6ec017",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Strategia z ostatnich zajęć - konwolucje",
   "id": "d60a765478ed9322"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ConvolutionModel(torch.nn.Module):\n",
    "    def __init__(self, channels: list[int]) -> None:\n",
    "        super(ConvolutionModel, self).__init__()\n",
    "\n",
    "        ### TODO: zdefiniuj model konwolucyjny na podstawie podanej listy rozmiarów kanałów,\n",
    "        ### Między konwolucjami użyj aktywacji ReLU oraz MaxPool2d z kernel_size=2\n",
    "        ### Na koniec dodaj warstwę Linear do klasyfikacji na 10 klas\n",
    "        ### Hint: użyj torch.nn.Sequential oraz torch.nn.Conv2d\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ### TODO: zaimplementuj funkcję forward"
   ],
   "id": "294760dc2260026",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "conv_model = ConvolutionModel([32, 64, 128]).to(device)\n",
    "### TODO: trenowanie modelu konwolucyjnego"
   ],
   "id": "f36cb97e1c2ae8fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Krok dalej - dlaczego mamy trenować od nowa?",
   "id": "9f93e598262c353c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "resnet18 = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
    "print(resnet18)"
   ],
   "id": "c7deaf13aabe48a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class ResNetModel(torch.nn.Module):\n",
    "    def __init__(self, base_model: torch.nn.Module) -> None:\n",
    "        super(ResNetModel, self).__init__()\n",
    "        ### TODO: zdefiniuj model na bazie podanego modelu bazowego\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ### TODO: zaimplementuj funkcję forward\n"
   ],
   "id": "f9686d40a579fd3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "final_model = ResNetModel(resnet18).to(device)",
   "id": "93dd5d5d64562e6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4f7f32c0f59928a1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
