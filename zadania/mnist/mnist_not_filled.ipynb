{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ffe3d362c0397b",
   "metadata": {},
   "source": [
    "# MNIST z twistem: Multi-task Learning\n",
    "\n",
    "Klasyczny MNIST to \"Hello World\" uczenia maszynowego. Dzisiaj trochę go **popsujemy**.\n",
    "\n",
    "### Zadanie\n",
    "Stworzyliśmy zmodyfikowany zbiór danych, w którym:\n",
    "1. Ok. **20%** obrazków zostało odbitych lustrzanie w poziomie (Horizontal Flip)\n",
    "2. Ok. **20%** obrazków zostało odbitych w pionie (Vertical Flip)\n",
    "\n",
    "Twoim celem jest zbudowanie sieci neuronowej, która **jednocześnie** przewidzi:\n",
    "1. Jaka cyfra jest na obrazku (0-9)\n",
    "2. Czy obrazek jest odbity w poziomie (tak/nie)\n",
    "3. Czy obrazek jest odbity w pionie (tak/nie)\n",
    "\n",
    "To zadanie typu **Multi-Task Learning** - jedna sieć z trzema \"głowami\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grading_criterion",
   "metadata": {},
   "source": [
    "## Kryterium oceny\n",
    "\n",
    "Jakość rozwiązania mierzymy za pomocą **accuracy** (dokładności) na zbiorze testowym.\n",
    "\n",
    "Accuracy obliczamy jako procent przykładów, dla których **wszystkie trzy predykcje** są poprawne:\n",
    "- cyfra (0-9)\n",
    "- odbicie poziome (H-flip)\n",
    "- odbicie pionowe (V-flip)\n",
    "\n",
    "### Punktacja\n",
    "\n",
    "Punktacja zależy od accuracy na zbiorze testowym:\n",
    "\n",
    "* jeśli accuracy ≥ 96% – dostajesz **1 punkt**,\n",
    "* jeśli accuracy ≤ 90% – dostajesz **0 punktów**,\n",
    "* w przedziale 90-96% – punkty są skalowane **liniowo**.\n",
    "\n",
    "$$\n",
    "\\text{punkty}(\\text{acc}) =\n",
    "\\begin{cases}\n",
    "1, & \\text{gdy } \\text{acc} \\ge 0.96,\\\\\n",
    "0, & \\text{gdy } \\text{acc} \\le 0.90,\\\\\n",
    "\\dfrac{\\text{acc} - 0.90}{0.06}, & \\text{w przeciwnym razie.}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "submission_format",
   "metadata": {},
   "source": [
    "## Format zgłoszenia rozwiązania\n",
    "\n",
    "Rozwiązaniem jest **jeden plik** w formacie `npz`, zapisany tak:\n",
    "\n",
    "```python\n",
    "np.savez(\n",
    "    \"solution.npz\",\n",
    "    digit=pred_digit,    # shape: (N,), dtype: int, wartości 0-9\n",
    "    h_flip=pred_h_flip,  # shape: (N,), dtype: int, wartości 0 lub 1\n",
    "    v_flip=pred_v_flip,  # shape: (N,), dtype: int, wartości 0 lub 1\n",
    ")\n",
    "```\n",
    "\n",
    "gdzie:\n",
    "* `N` to liczba przykładów w zbiorze testowym,\n",
    "* `pred_digit` – przewidywane cyfry (0-9),\n",
    "* `pred_h_flip` – przewidywane odbicia poziome (0 lub 1),\n",
    "* `pred_v_flip` – przewidywane odbicia pionowe (0 lub 1)."
   ]
  },
  {
   "cell_type": "code",
   "id": "d1f2bb09b1797de3",
   "metadata": {},
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Ziarno losowości dla powtarzalności\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Urządzenie: {DEVICE}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6705c62b3e04264b",
   "metadata": {},
   "source": [
    "## 1. Wczytywanie Danych\n",
    "\n",
    "Wczytujemy przygotowane zbiory danych z plików."
   ]
  },
  {
   "cell_type": "code",
   "id": "load_data",
   "metadata": {},
   "source": "# Wczytywanie danych z jednego pliku\ndata = np.load(\"data.npz\")\n\n# Dane treningowe\ntrain_images = torch.from_numpy(data[\"train_images\"]).float()\ntrain_digits = torch.from_numpy(data[\"train_digit\"]).long()\ntrain_h = torch.from_numpy(data[\"train_h_flip\"]).float()\ntrain_v = torch.from_numpy(data[\"train_v_flip\"]).float()\n\n# Dane walidacyjne\nval_images = torch.from_numpy(data[\"val_images\"]).float()\nval_digits = torch.from_numpy(data[\"val_digit\"]).long()\nval_h = torch.from_numpy(data[\"val_h_flip\"]).float()\nval_v = torch.from_numpy(data[\"val_v_flip\"]).float()\n\n# Dane testowe (tylko obrazki)\ntest_images = torch.from_numpy(data[\"test_images\"]).float()\n\nprint(f\"Zbiór treningowy: {len(train_images)} obrazków\")\nprint(f\"Zbiór walidacyjny: {len(val_images)} obrazków\")\nprint(f\"Zbiór testowy: {len(test_images)} obrazków\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "create_loaders",
   "metadata": {},
   "source": [
    "# Tworzenie DataLoaderów\n",
    "class TwistedMNISTDataset(Dataset):\n",
    "    def __init__(self, images, digits, h_flips, v_flips):\n",
    "        self.images = images\n",
    "        self.digits = digits\n",
    "        self.h_flips = h_flips\n",
    "        self.v_flips = v_flips\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.digits[idx], self.h_flips[idx], self.v_flips[idx]\n",
    "\n",
    "\n",
    "train_ds = TwistedMNISTDataset(train_images, train_digits, train_h, train_v)\n",
    "val_ds = TwistedMNISTDataset(val_images, val_digits, val_h, val_v)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=1000, shuffle=False)\n",
    "test_loader = DataLoader(test_images, batch_size=1000, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "58aaf211555699ed",
   "metadata": {},
   "source": [
    "## 2. Wizualizacja\n",
    "\n",
    "Zobaczmy przykłady z każdą kombinacją transformacji."
   ]
  },
  {
   "cell_type": "code",
   "id": "eb95dfd445758085",
   "metadata": {},
   "source": [
    "def show_examples(dataset: TwistedMNISTDataset, n: int = 8) -> None:\n",
    "    \"\"\"Pokaż przykładowe obrazki z datasetu.\"\"\"\n",
    "    fig, axes = plt.subplots(2, n // 2, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(n):\n",
    "        img, digit, h, v = dataset[i]\n",
    "        axes[i].imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "        title = f\"Cyfra: {digit}\"\n",
    "        if h:\n",
    "            title += \" [H]\"\n",
    "        if v:\n",
    "            title += \" [V]\"\n",
    "        axes[i].set_title(title)\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_examples(train_ds)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "679fc646c1e1d808",
   "metadata": {},
   "source": [
    "## 3. Model Multi-Head CNN\n",
    "\n",
    "Model składa się z:\n",
    "1. **Backbone**: Wspólne warstwy konwolucyjne\n",
    "2. **Heads**: Trzy osobne \"głowy\" - po jednej dla każdego zadania\n",
    "\n",
    "### TODO: Uzupełnij definicję modelu\n",
    "\n",
    "Stwórz sieć z:\n",
    "- Wspólną częścią konwolucyjną (backbone)\n",
    "- Trzema osobnymi \"głowami\":\n",
    "  - `digit_head` - klasyfikacja cyfr (10 klas)\n",
    "  - `h_flip_head` - wykrywanie odbicia poziomego (binarna)\n",
    "  - `v_flip_head` - wykrywanie odbicia pionowego (binarna)"
   ]
  },
  {
   "cell_type": "code",
   "id": "2a150046f5afd576",
   "metadata": {},
   "source": [
    "class MultiHeadMNIST(nn.Module):\n",
    "    \"\"\"Sieć z trzema głowami: cyfra, h-flip, v-flip.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO: Zdefiniuj warstwy modelu\n",
    "        pass\n",
    "\n",
    "    def forward(self, x: Tensor) -> tuple[Tensor, Tensor, Tensor]:\n",
    "        # TODO: Zaimplementuj forward pass\n",
    "        # Zwróć tuple: (digit_out, h_flip_out, v_flip_out) - wszystkie 3 wartości PRZED softmax/sigmoid\n",
    "        pass"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a7f0d3ea0136b679",
   "metadata": {},
   "source": [
    "## 4. Trening\n",
    "\n",
    "### TODO: Uzupełnij pętlę treningową\n",
    "\n",
    "Użyj:\n",
    "- `CrossEntropyLoss` dla klasyfikacji cyfr\n",
    "- `BCEWithLogitsLoss` dla wykrywania odbić (binarna klasyfikacja)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6b167e81e1b32dd",
   "metadata": {},
   "source": [
    "def evaluate(model: nn.Module, loader: DataLoader) -> dict:\n",
    "    \"\"\"Ewaluacja modelu na danym zbiorze.\"\"\"\n",
    "    model.eval()\n",
    "    correct_digit = 0\n",
    "    correct_h = 0\n",
    "    correct_v = 0\n",
    "    correct_all = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels_digit, labels_h, labels_v in loader:\n",
    "            images = images.to(DEVICE)\n",
    "            out_digit, out_h, out_v = model(images)\n",
    "\n",
    "            # Predykcje\n",
    "            pred_digit = out_digit.argmax(dim=1)\n",
    "            pred_h = (torch.sigmoid(out_h) > 0.5).squeeze()\n",
    "            pred_v = (torch.sigmoid(out_v) > 0.5).squeeze()\n",
    "\n",
    "            # Zliczanie poprawnych\n",
    "            digit_correct = pred_digit == labels_digit.to(DEVICE)\n",
    "            h_correct = pred_h == labels_h.to(DEVICE)\n",
    "            v_correct = pred_v == labels_v.to(DEVICE)\n",
    "\n",
    "            correct_digit += digit_correct.sum().item()\n",
    "            correct_h += h_correct.sum().item()\n",
    "            correct_v += v_correct.sum().item()\n",
    "            correct_all += (digit_correct & h_correct & v_correct).sum().item()\n",
    "            total += labels_digit.size(0)\n",
    "\n",
    "    return {\n",
    "        \"all\": 100 * correct_all / total,\n",
    "        \"digit\": 100 * correct_digit / total,\n",
    "        \"h_flip\": 100 * correct_h / total,\n",
    "        \"v_flip\": 100 * correct_v / total,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    epochs: int = 10,\n",
    ") -> None:\n",
    "    \"\"\"Trenuj model przez zadaną liczbę epok.\"\"\"\n",
    "\n",
    "    # TODO: Zdefiniuj optymalizator i funkcje straty\n",
    "    # optimizer = ...\n",
    "    # criterion_digit = nn.CrossEntropyLoss()\n",
    "    # criterion_flip = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for images, labels_digit, labels_h, labels_v in train_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels_digit = labels_digit.to(DEVICE)\n",
    "            labels_h = labels_h.to(DEVICE).unsqueeze(1)\n",
    "            labels_v = labels_v.to(DEVICE).unsqueeze(1)\n",
    "\n",
    "            # TODO: Uzupełnij pętlę treningową\n",
    "            # 1. Wyzeruj gradienty\n",
    "            # 2. Przepuść obrazy przez model\n",
    "            # 3. Oblicz 3 straty i zsumuj je\n",
    "            # 4. Backpropagacja\n",
    "            # 5. Krok optymalizatora\n",
    "            pass\n",
    "\n",
    "        # Ewaluacja na zbiorze treningowym i walidacyjnym\n",
    "        train_metrics = evaluate(model, train_loader)\n",
    "        val_metrics = evaluate(model, val_loader)\n",
    "\n",
    "        print(\n",
    "            f\"Epoka {epoch:2d} | \"\n",
    "            f\"Train: {train_metrics['all']:.1f}% | \"\n",
    "            f\"Val: {val_metrics['all']:.1f}% | \"\n",
    "            f\"(Cyfry: {val_metrics['digit']:.1f}%, \"\n",
    "            f\"H: {val_metrics['h_flip']:.1f}%, \"\n",
    "            f\"V: {val_metrics['v_flip']:.1f}%)\"\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c786285a6d5af7e6",
   "metadata": {},
   "source": [
    "model = MultiHeadMNIST().to(DEVICE)\n",
    "print(f\"Parametry modelu: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "train_model(model, train_loader, val_loader, epochs=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bf4c453034145627",
   "metadata": {},
   "source": [
    "## 5. Analiza Wyników\n",
    "\n",
    "Zobaczmy macierz pomyłek (confusion matrix) dla cyfr."
   ]
  },
  {
   "cell_type": "code",
   "id": "88bd210967d21662",
   "metadata": {},
   "source": [
    "def plot_confusion_matrix(model: nn.Module, loader: DataLoader) -> None:\n",
    "    \"\"\"Narysuj macierz pomyłek dla predykcji cyfr.\"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "\n",
    "    model.eval()\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels_digit, _, _ in loader:\n",
    "            images = images.to(DEVICE)\n",
    "            out_digit, _, _ = model(images)\n",
    "            pred = out_digit.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "            all_true.extend(labels_digit.numpy())\n",
    "            all_pred.extend(pred)\n",
    "\n",
    "    cm = confusion_matrix(all_true, all_pred)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.xlabel(\"Predykcja\")\n",
    "    plt.ylabel(\"Prawda\")\n",
    "    plt.title(\"Macierz pomyłek - rozpoznawanie cyfr\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_confusion_matrix(model, val_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f6xqrsdqhml",
   "metadata": {},
   "source": [
    "def plot_flip_accuracy_by_digit(model: nn.Module, loader: DataLoader) -> None:\n",
    "    \"\"\"Pokaż accuracy dla H-flip i V-flip w podziale na cyfry.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Słowniki: cyfra -> (correct_h, correct_v, total)\n",
    "    stats = {d: {\"correct_h\": 0, \"correct_v\": 0, \"total\": 0} for d in range(10)}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels_digit, labels_h, labels_v in loader:\n",
    "            images = images.to(DEVICE)\n",
    "            _, out_h, out_v = model(images)\n",
    "            \n",
    "            pred_h = (torch.sigmoid(out_h) > 0.5).squeeze().cpu()\n",
    "            pred_v = (torch.sigmoid(out_v) > 0.5).squeeze().cpu()\n",
    "            \n",
    "            for i, digit in enumerate(labels_digit.numpy()):\n",
    "                stats[digit][\"total\"] += 1\n",
    "                if pred_h[i] == labels_h[i]:\n",
    "                    stats[digit][\"correct_h\"] += 1\n",
    "                if pred_v[i] == labels_v[i]:\n",
    "                    stats[digit][\"correct_v\"] += 1\n",
    "    \n",
    "    # Oblicz accuracy\n",
    "    digits = list(range(10))\n",
    "    acc_h = [100 * stats[d][\"correct_h\"] / stats[d][\"total\"] for d in digits]\n",
    "    acc_v = [100 * stats[d][\"correct_v\"] / stats[d][\"total\"] for d in digits]\n",
    "    \n",
    "    # Wykres\n",
    "    x = np.arange(10)\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    bars_h = ax.bar(x - width/2, acc_h, width, label=\"H-Flip\", color=\"steelblue\")\n",
    "    bars_v = ax.bar(x + width/2, acc_v, width, label=\"V-Flip\", color=\"coral\")\n",
    "    \n",
    "    ax.set_xlabel(\"Cyfra\")\n",
    "    ax.set_ylabel(\"Accuracy (%)\")\n",
    "    ax.set_title(\"Accuracy wykrywania odbić w podziale na cyfry\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(digits)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 105)\n",
    "    \n",
    "    # Dodaj wartości na słupkach\n",
    "    for bar in bars_h:\n",
    "        ax.annotate(f'{bar.get_height():.1f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "    for bar in bars_v:\n",
    "        ax.annotate(f'{bar.get_height():.1f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),\n",
    "                    ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # Zaznacz cyfry symetryczne\n",
    "    ax.axvspan(-0.5, 0.5, alpha=0.1, color='green', label='Symetryczne')\n",
    "    ax.axvspan(0.5, 1.5, alpha=0.1, color='green')\n",
    "    ax.axvspan(7.5, 8.5, alpha=0.1, color='green')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Podsumowanie\n",
    "    symmetric = [0, 1, 8]\n",
    "    asymmetric = [2, 3, 4, 5, 6, 7, 9]\n",
    "    \n",
    "    avg_h_sym = np.mean([acc_h[d] for d in symmetric])\n",
    "    avg_h_asym = np.mean([acc_h[d] for d in asymmetric])\n",
    "    avg_v_sym = np.mean([acc_v[d] for d in symmetric])\n",
    "    avg_v_asym = np.mean([acc_v[d] for d in asymmetric])\n",
    "    \n",
    "    print(f\"Średnia accuracy H-Flip: symetryczne (0,1,8): {avg_h_sym:.1f}% | asymetryczne: {avg_h_asym:.1f}%\")\n",
    "    print(f\"Średnia accuracy V-Flip: symetryczne (0,1,8): {avg_v_sym:.1f}% | asymetryczne: {avg_v_asym:.1f}%\")\n",
    "\n",
    "\n",
    "plot_flip_accuracy_by_digit(model, val_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dc4a245c67b2bdf5",
   "metadata": {},
   "source": [
    "## 6. Przykłady Błędów"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b969d29f7295c73",
   "metadata": {},
   "source": [
    "def show_errors(model: nn.Module, dataset: TwistedMNISTDataset, n: int = 8) -> None:\n",
    "    \"\"\"Pokaż przykłady błędnych predykcji (błąd w dowolnym z trzech zadań).\"\"\"\n",
    "    model.eval()\n",
    "    errors = []\n",
    "\n",
    "    def format_label(digit: int, h: bool, v: bool) -> str:\n",
    "        \"\"\"Formatuj etykietę jako 'cyfra [H?] [V?]'.\"\"\"\n",
    "        s = str(digit)\n",
    "        s += \" [H]\" if h else \" [ ]\"\n",
    "        s += \" [V]\" if v else \" [ ]\"\n",
    "        return s\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            img, true_digit, true_h, true_v = dataset[i]\n",
    "            out_digit, out_h, out_v = model(img.unsqueeze(0).to(DEVICE))\n",
    "            \n",
    "            pred_digit = out_digit.argmax().item()\n",
    "            pred_h = (torch.sigmoid(out_h) > 0.5).item()\n",
    "            pred_v = (torch.sigmoid(out_v) > 0.5).item()\n",
    "\n",
    "            # Błąd jeśli dowolny z elementów nie pasuje\n",
    "            digit_wrong = pred_digit != true_digit\n",
    "            h_wrong = pred_h != true_h\n",
    "            v_wrong = pred_v != true_v\n",
    "\n",
    "            if digit_wrong or h_wrong or v_wrong:\n",
    "                errors.append({\n",
    "                    \"idx\": i,\n",
    "                    \"true_digit\": true_digit.item(), \"true_h\": bool(true_h), \"true_v\": bool(true_v),\n",
    "                    \"pred_digit\": pred_digit, \"pred_h\": pred_h, \"pred_v\": pred_v,\n",
    "                    \"digit_wrong\": digit_wrong, \"h_wrong\": h_wrong, \"v_wrong\": v_wrong,\n",
    "                })\n",
    "\n",
    "            if len(errors) >= n:\n",
    "                break\n",
    "\n",
    "    if not errors:\n",
    "        print(\"Brak błędów!\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(2, n // 2, figsize=(14, 7))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, err in enumerate(errors):\n",
    "        img, _, _, _ = dataset[err[\"idx\"]]\n",
    "        axes[i].imshow(img.squeeze(), cmap=\"gray\")\n",
    "\n",
    "        true_str = format_label(err[\"true_digit\"], err[\"true_h\"], err[\"true_v\"])\n",
    "        pred_str = format_label(err[\"pred_digit\"], err[\"pred_h\"], err[\"pred_v\"])\n",
    "        \n",
    "        # Kolorowanie tytułu w zależności od typu błędu\n",
    "        error_types = []\n",
    "        if err[\"digit_wrong\"]:\n",
    "            error_types.append(\"D\")\n",
    "        if err[\"h_wrong\"]:\n",
    "            error_types.append(\"H\")\n",
    "        if err[\"v_wrong\"]:\n",
    "            error_types.append(\"V\")\n",
    "        \n",
    "        title = f\"True: {true_str}\\nPred: {pred_str}\\nBłąd: {','.join(error_types)}\"\n",
    "        axes[i].set_title(title, color=\"red\", fontsize=9)\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.suptitle(\"Błędne predykcje (D=cyfra, H=h-flip, V=v-flip)\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_errors(model, val_ds)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "test_prediction_header",
   "metadata": {},
   "source": [
    "## 7. Predykcja na zbiorze testowym i zapis rozwiązania"
   ]
  },
  {
   "cell_type": "code",
   "id": "test_prediction",
   "metadata": {},
   "source": [
    "def predict_test(model: nn.Module, test_loader: DataLoader) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Generuj predykcje dla zbioru testowego.\"\"\"\n",
    "    model.eval()\n",
    "    all_digits = []\n",
    "    all_h = []\n",
    "    all_v = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            out_digit, out_h, out_v = model(images)\n",
    "\n",
    "            pred_digit = out_digit.argmax(dim=1).cpu().numpy()\n",
    "            pred_h = (torch.sigmoid(out_h) > 0.5).squeeze().cpu().numpy().astype(int)\n",
    "            pred_v = (torch.sigmoid(out_v) > 0.5).squeeze().cpu().numpy().astype(int)\n",
    "\n",
    "            all_digits.extend(pred_digit)\n",
    "            all_h.extend(pred_h)\n",
    "            all_v.extend(pred_v)\n",
    "\n",
    "    return np.array(all_digits), np.array(all_h), np.array(all_v)\n",
    "\n",
    "\n",
    "# Generowanie predykcji\n",
    "pred_digit, pred_h, pred_v = predict_test(model, test_loader)\n",
    "\n",
    "print(f\"Liczba predykcji: {len(pred_digit)}\")\n",
    "print(f\"Przykładowe predykcje cyfr: {pred_digit[:10]}\")\n",
    "print(f\"Przykładowe predykcje H-flip: {pred_h[:10]}\")\n",
    "print(f\"Przykładowe predykcje V-flip: {pred_v[:10]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "save_solution",
   "metadata": {},
   "source": [
    "# Zapisywanie rozwiązania\n",
    "assert pred_digit.shape == (len(test_images),), f\"Nieprawidłowe wymiary digit: {pred_digit.shape}\"\n",
    "assert pred_h.shape == (len(test_images),), f\"Nieprawidłowe wymiary h_flip: {pred_h.shape}\"\n",
    "assert pred_v.shape == (len(test_images),), f\"Nieprawidłowe wymiary v_flip: {pred_v.shape}\"\n",
    "\n",
    "np.savez(\n",
    "    \"solution.npz\",\n",
    "    digit=pred_digit,\n",
    "    h_flip=pred_h,\n",
    "    v_flip=pred_v,\n",
    ")\n",
    "print(\"Zapisano plik 'solution.npz' z wynikami dla zbioru testowego.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7ef4305f42ddaae3",
   "metadata": {},
   "source": [
    "## Wnioski\n",
    "\n",
    "1. **Symetria to problem** - Cyfry symetryczne (0, 1, 8) są trudne do wykrycia czy są odbite\n",
    "2. **Multi-task learning działa** - Jedna sieć uczy się trzech zadań jednocześnie\n",
    "3. **Eksperyment**: Spróbuj zmienić wagi strat i zobacz jak wpływa to na wyniki"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}